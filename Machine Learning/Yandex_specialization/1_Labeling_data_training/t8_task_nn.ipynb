{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронные сети: зависимость ошибки и обучающей способности от числа нейронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вы будете настраивать двуслойную нейронную сеть для решения задачи многоклассовой классификации. Предлагается выполнить процедуры загрузки и разбиения входных данных, обучения сети и подсчета ошибки классификации. Предлагается определить оптимальное количество нейронов в скрытом слое сети. Нужно так подобрать число нейронов, чтобы модель была с одной стороны несложной, а с другой стороны давала бы достаточно точный прогноз и не переобучалась. Цель задания -- показать, как зависит точность и обучающая способность сети от ее сложности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения задачи многоклассовой классификации предлагается воспользоваться библиотекой построения нейронных сетей [pybrain](http://pybrain.org/). Библиотека содержит основные модули инициализации двуслойной нейронной сети прямого распространения, оценки ее параметров с помощью метода обратного распространения ошибки (backpropagation) и подсчета ошибки.\n",
    "\n",
    "Установить библиотеку pybrain можно с помощью стандартной системы управления пакетами pip:\n",
    "\n",
    "```\n",
    "pip install pybrain\n",
    "```\n",
    "Кроме того, для установки библиотеки можно использовать и другие способы, приведенные в [документации](https://github.com/pybrain/pybrain/wiki/installation). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Используемые данные\n",
    "\n",
    "Рассматривается задача оценки качества вина по его физико-химическим свойствам [1]. Данные размещены в [открытом доступе](https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) в репозитории UCI  и содержат 1599 образцов красного вина, описанных 11 признаками, среди которых -- кислотность, процентное содержание сахара, алкоголя и пр. Кроме того, каждому объекту поставлена в соответствие оценка качества по шкале от 0 до 10. Требуется восстановить оценку качества вина по исходному признаковому описанию.\n",
    "\n",
    "[1] P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling wine preferences by data mining from physicochemical properties.  In Decision Support Systems, Elsevier, 47(4):547-553, 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполним инициализацию основных используемых модулей\n",
    "\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), 'data', 'winequality-red.csv')\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    print('Path does not exists: {0}'.format(path))\n",
    "else:\n",
    "    df = pd.read_csv(path, delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим из данных целевую переменную. Классы в задаче являются несбалинсированными: основной доле объектов поставлена оценка качества от 5 до 7. Приведем задачу к трехклассовой: объектам с оценкой качества меньше пяти поставим оценку 5, а объектам с оценкой качества больше семи поставим 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.7 # Разделение данных на обучающую и контрольную части в пропорции 70/30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.quality.values\n",
    "np.place(y, y < 5, 5)\n",
    "np.place(y, y > 7, 7)\n",
    "y -= min(y)\n",
    "X = df.iloc[:, :-1].values\n",
    "X = normalize(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=(1.-TRAIN_SIZE), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21848288, 0.01358457, 0.00711271, 0.06320607, 0.00222649,\n",
       "       0.31207977, 0.83358734, 0.02582182, 0.08577216, 0.01691227,\n",
       "       0.27292187])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двуслойная нейронная сеть\n",
    "\n",
    "Двуслойная нейронная сеть представляет собой функцию распознавания, которая може быть записана в виде следующей суперпозиции:\n",
    "\n",
    "$f(x,W)=h^{(2)}\\left(\\sum\\limits_{i=1}^D w_i^{(2)}h^{(1)}\\left(\\sum\\limits_{j=1}^n w_{ji}^{(1)}x_j+b_i^{(1)}\\right)+b^{(2)}\\right)$, где\n",
    "\n",
    "$x$ -- исходный объект (сорт вина, описанный 11 признаками), $x_j$ -- соответствующий признак,\n",
    "\n",
    "$n$ --  количество нейронов во входном слое сети, совпадающее с количеством признаков,\n",
    "\n",
    "$D$ --  количество нейронов в скрытом слое сети,\n",
    "\n",
    "$w_i^{(2)}, w_{ji}^{(1)}, b_i^{(1)}, b^{(2)}$ --  параметры сети, соответствующие весам нейронов,\n",
    "\n",
    "$h^{(1)}, h^{(2)}$ -- функции активации.\n",
    "\n",
    "В качестве функции активации на скрытом слое сети используется линейная функция. На выходном слое сети используется функция активации softmax, являющаяся обобщением сигмоидной функции на многоклассовый случай:\n",
    "\n",
    "$y_k=\\text{softmax}_k(a_1,...,a_k)=\\frac{\\exp(a_k)}{\\sum_{k=1}^K\\exp(a_k)}.$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка параметров сети\n",
    "\n",
    "Оптимальные параметры сети $W_{opt}$ определяются путем минимизации функции ошибки:\n",
    "\n",
    "$W_{opt}=\\arg\\min\\limits_{W}L(W)+\\lambda\\|W\\|^2$.\n",
    "\n",
    "Здесь $L(W)$ является функцией ошибки многоклассовой классификации,\n",
    "\n",
    "$L(W)=- \\sum^N_{n=1}\\sum^K_{k=1} t_{kn} log(y_{kn}),$\n",
    "\n",
    "$t_{kn}$ -- бинарно закодированные метки классов, $K$ -- количество меток, $N$ -- количество объектов,\n",
    "\n",
    "а $\\lambda\\|W\\|^2$ является регуляризующим слагаемым, контролирующим суммарный вес параметров сети и предотвращающий эффект переобучения.\n",
    "\n",
    "Оптимизация параметров выполняется методом обратного распространения ошибки (backpropagation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку основных модулей: ClassificationDataSet -- структура данных pybrain, buildNetwork -- инициализация нейронной сети, BackpropTrainer -- оптимизация параметров сети методом backpropagation, SoftmaxLayer -- функция softmax, соответствующая выходному слою сети, percentError -- функцию подсчета ошибки классификации (доля неправильных ответов). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain.datasets import ClassificationDataSet # Структура данных pybrain\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.structure.modules import SoftmaxLayer\n",
    "from pybrain.utilities import percentError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем основные параметры задачи: HIDDEN_NEURONS_NUM -- количество нейронов скрытого слоя, MAX_EPOCHS -- максимальное количество итераций алгоритма оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение основных констант\n",
    "HIDDEN_NEURONS_NUM = 100 # Количество нейронов, содержащееся в скрытом слое сети\n",
    "MAX_EPOCHS = 100 # Максимальное число итераций алгоритма оптимизации параметров сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем структуру данных ClassificationDataSet, используемую библиотекой pybrain. Для инициализации структура принимает два аргумента: количество признаков *np.shape(X)[1]* и количество различных меток классов *len(np.unique(y))*.\n",
    "\n",
    "Кроме того, произведем бинаризацию целевой переменной с помощью функции *_convertToOneOfMany( )* и разбиение данных на обучающую и контрольную части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конвертация данных в структуру ClassificationDataSet\n",
    "# Обучающая часть\n",
    "ds_train = ClassificationDataSet(np.shape(X)[1], nb_classes=len(np.unique(y_train)))\n",
    "# Первый аргумент -- количество признаков np.shape(X)[1], второй аргумент -- количество меток классов len(np.unique(y_train)))\n",
    "ds_train.setField('input', X_train) # Инициализация объектов\n",
    "ds_train.setField('target', y_train[:, np.newaxis]) # Инициализация ответов; np.newaxis создает вектор-столбец\n",
    "ds_train._convertToOneOfMany( ) # Бинаризация вектора ответов\n",
    "# Контрольная часть\n",
    "ds_test = ClassificationDataSet(np.shape(X)[1], nb_classes=len(np.unique(y_train)))\n",
    "ds_test.setField('input', X_test)\n",
    "ds_test.setField('target', y_test[:, np.newaxis])\n",
    "ds_test._convertToOneOfMany( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем двуслойную сеть и произведем оптимизацию ее параметров. Аргументами для инициализации являются:\n",
    "\n",
    "ds.indim -- количество нейронов на входном слое сети, совпадает с количеством признаков (в нашем случае 11),\n",
    "\n",
    "HIDDEN_NEURONS_NUM -- количество нейронов в скрытом слое сети,\n",
    "\n",
    "ds.outdim -- количество нейронов на выходном слое сети, совпадает с количеством различных меток классов (в нашем случае 3),\n",
    "\n",
    "SoftmaxLayer -- функция softmax, используемая на выходном слое для решения задачи многоклассовой классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0) # Зафиксируем seed для получения воспроизводимого результата\n",
    "\n",
    "# Построение сети прямого распространения (Feedforward network)\n",
    "net = buildNetwork(ds_train.indim, HIDDEN_NEURONS_NUM, ds_train.outdim, outclass=SoftmaxLayer)\n",
    "# ds.indim -- количество нейронов входного слоя, равне количеству признаков\n",
    "# ds.outdim -- количество нейронов выходного слоя, равное количеству меток классов\n",
    "# SoftmaxLayer -- функция активации, пригодная для решения задачи многоклассовой классификации\n",
    "\n",
    "# Инициализируем веса сети для получения воспроизводимого результата\n",
    "init_params = np.random.random((len(net.params)))\n",
    "net._setParameters(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Выполним оптимизацию параметров сети. График ниже показывает сходимость функции ошибки на обучающей/контрольной части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "random.seed(0)\n",
    "# Модуль настройки параметров pybrain использует модуль random; зафиксируем seed для получения воспроизводимого результата\n",
    "trainer = BackpropTrainer(net, dataset=ds_train) # Инициализируем модуль оптимизации\n",
    "err_train, err_val = trainer.trainUntilConvergence(maxEpochs=MAX_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "line_train = plt.plot(err_train, 'b', err_val, 'r') # Построение графика\n",
    "xlab = plt.xlabel('Iterations')\n",
    "ylab = plt.ylabel('Error')\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем значение доли неправильных ответов на обучающей и контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on train:  49.0616621984 %\n",
      "Error on test:  46.0416666667 %\n"
     ]
    }
   ],
   "source": [
    "res_train = net.activateOnDataset(ds_train).argmax(axis=1) # Подсчет результата на обучающей выборке\n",
    "print 'Error on train: ', percentError(res_train, ds_train['target'].argmax(axis=1)), '%' # Подсчет ошибки\n",
    "res_test = net.activateOnDataset(ds_test).argmax(axis=1) # Подсчет результата на тестовой выборке\n",
    "print 'Error on test: ', percentError(res_test, ds_test['target'].argmax(axis=1)), '%' # Подсчет ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание. Определение оптимального числа нейронов.\n",
    "В задании требуется исследовать зависимость ошибки на контрольной выборке в зависимости от числа нейронов в скрытом слое сети. Количество нейронов, по которому предполагается провести перебор, записано в векторе \n",
    "```\n",
    "hidden_neurons_num = [50, 100, 200, 500, 700, 1000]\n",
    "```\n",
    "\n",
    "1. Для фиксированного разбиения на обучающую и контрольную части подсчитайте долю неправильных ответов (ошибок) классификации на обучении/контроле в зависимости от количества нейронов в скрытом слое сети. Запишите результаты в массивы ```res_train_vec``` и ```res_test_vec```, соответственно. С помощью функции ```plot_classification_error``` постройте график зависимости ошибок на обучении/контроле от количества нейронов. Являются ли графики ошибок возрастающими/убывающими? При каком количестве нейронов достигается минимум ошибок классификации?\n",
    "\n",
    "2. С помощью функции ```write_answer_nn``` запишите в выходной файл число: количество нейронов в скрытом слое сети, для которого достигается минимум ошибки классификации на контрольной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Complete: ', 0)\n",
      "('Complete: ', 1)\n",
      "('Complete: ', 2)\n",
      "('Complete: ', 3)\n",
      "('Complete: ', 4)\n",
      "('Complete: ', 5)\n",
      "Done\n",
      "Wall time: 6min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "hidden_neurons_num = np.array([50, 100, 200, 500, 700, 1000])\n",
    "res_train_vec = np.zeros(hidden_neurons_num.shape[0], dtype=float)\n",
    "res_test_vec = np.zeros(hidden_neurons_num.shape[0], dtype=float)\n",
    "\n",
    "\n",
    "for ID, nnum in enumerate(hidden_neurons_num):\n",
    "    cur_net = buildNetwork(\n",
    "        ds_train.indim, nnum, \n",
    "        ds_train.outdim, outclass=SoftmaxLayer\n",
    "    )\n",
    "    init_params = np.random.random((len(cur_net.params)))\n",
    "    cur_net._setParameters(init_params)\n",
    "    \n",
    "    trainer = BackpropTrainer(cur_net, dataset=ds_train)\n",
    "    err_train, err_val = trainer.trainUntilConvergence(maxEpochs=MAX_EPOCHS)\n",
    "    \n",
    "    res_train_vec[ID] = np.min(err_train)\n",
    "    res_test_vec[ID] = np.min(err_val)\n",
    "    \n",
    "    print('Complete: ', ID)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10014896 0.09681867 0.09470403 0.09476989 0.10616738 0.12148877]\n",
      "1000\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(res_test_vec)\n",
    "print(hidden_neurons_num[res_train_vec.argmax()])\n",
    "n_opt = hidden_neurons_num[res_test_vec.argmin()]\n",
    "print(n_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2.txt', 'w') as f:\n",
    "    f.write(str(n_opt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
