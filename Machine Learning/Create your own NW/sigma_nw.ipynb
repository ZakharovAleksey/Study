{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Модель нейронной сети, которая позволяет проводить распознование рукописных цифр. \n",
    "\n",
    "Модель выполнена по книге *Тарик Рашид - Создаем нейронную сеть* (https://www.ozon.ru/context/detail/id/141796497/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение нейронной сети.\n",
    "\n",
    "## Описание основных формул и идей.\n",
    "\n",
    "Допустим у нас трехслойная нейронная сеть, с тремя слоями:\n",
    "$$\n",
    "    input \\rightarrow hidden \\rightarrow output\n",
    "$$\n",
    "\n",
    "В процессе обучения выделяют следующие шаги (тут $W$ - это **матрица** весов):\n",
    "\n",
    "1. Прямой проход (суммирование всех взвешенных input-ов). Получаем промежуточный output.\n",
    "    - Выход hidden слоя: $O_{hid} = W_{inp, hid} \\times I_{inp}$\n",
    "    - Выход output слоя (одновременно и выход сети): $O_{out} = W_{hid, out} \\times I_{hid}$\n",
    "\n",
    "```pyhton\n",
    "    hidden_input = np.dot(self.wih, inputs)\n",
    "```\n",
    "\n",
    "\n",
    "2. Применяем функцию активации к каждому из промежуточных output-ов.\n",
    "    - Выход hidden слоя: $O_{hid} = sigm(W_{inp, hid} \\times I_{inp})$\n",
    "    - Выход output слоя: $O_{out} = sigm(W_{hid, out} \\times I_{hid})$\n",
    "\n",
    "```pyhton\n",
    "    hidden_output = self.act_func(hidden_input)\n",
    "```\n",
    "\n",
    "**Промежуточный итог**: завершился прямой проход нейронной сети. Как результат на выходном слое у нас есть итоговые предсказания.\n",
    "\n",
    "3. Вычисление ошибки предсказания для output слоя (используем квадратичную ошибку).\n",
    "    - Величинаа ошибки: $E_{out} = (expect_{out} - O_{out})^{2}$\n",
    "\n",
    "```pyhton\n",
    "    out_errors = targets - out_output\n",
    "```\n",
    "\n",
    "4. Обратное распростронение ошибки (вычисление ошибки для hidden слоя, и других если бы они были).\n",
    "    - Величина ошибки: $E_{hid} = W_{hid, out}^{T} \\times E{out}$\n",
    "\n",
    "```pyhton\n",
    "    hidden_errors = np.dot(self.who.T, out_errors)\n",
    "```\n",
    "\n",
    "**Промежуточный итог**: тут показано как вычислять ошибку предсказания для output слоя и всех предыдущих при движении в обратном направлении, то есть от $output \\rightarrow input$.\n",
    "\n",
    "P.S. Oшибка каждого нейрона делится между нейронами которые сформировали выход данного нейрона, пропорционально весам связи. \n",
    "Мы просто не нормируем на сумму всех весов по столбцу, так как это не особо важно.\n",
    "\n",
    "5. Обновление весовых коэффициентов (главное в нейронной сети).\n",
    "    - Весовые коэффициенты hidden/output слоев: \n",
    "    $W_{hid, out} = W_{hid, out} - \\alpha \\partial E_{out}/\\partial W_{hid, out}$\n",
    "    - Весовые коэффициент input/hidden слоев: \n",
    "    $W_{inp, hid} = W_{inp, hid} - \\alpha \\partial E_{hid}/\\partial W_{inp, hid}$\n",
    "\n",
    "```pyhton\n",
    "    self.who += self.lr * np.dot( (out_errors * out_output * (1.0 - out_output)), np.transpose(hidden_output) )\n",
    "```\n",
    "\n",
    "**Окончательный итог**: мы научились обновлять весовые коэффициенты нейронной сети используя градиентный спуск."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Краткое описание алгоритма обучения.\n",
    "\n",
    "Таким образом, мы выполняем следующую последовтельность действий:\n",
    "1. Прямой проход от последовательно от input слоя до output слоя(см. выше пункты 1 и 2). В итоге у нас есть предсказание нейронной сети.\n",
    "2. Вычисление ошибки предсказания для output слоя (см. пункт 3.)\n",
    "3. Вычислить ошибку на предыдущем для output слоя (см. пункт 4.)\n",
    "4. Модифицировать весовые коэффициенты между output слоем и предыдущим (см. пункт 5.)\n",
    "5. Повторять пункты (3-4) до тех пор, пока не дойдем до input слоя (таким образом мы обновим все веса сети)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример расчета градиента функции.\n",
    "\n",
    "Допустим при обучении используется квадратичная функция ошибки: $E_{out} = (expected - output)^{2}$.\n",
    "\n",
    "Рассмотрим как будет выглядеть выражение для обновление весов (пункт 5) в данном виде:\n",
    "$$\n",
    "    w_{hid, out} = w_{hid, out} - \\alpha \\frac{\\partial E_{out}}{\\partial W_{hid, out}}.\n",
    "$$\n",
    "\n",
    "Рассмотрим подробнее частную производную от ошибки:\n",
    "$$\n",
    "    \\frac{\\partial E_{out}}{\\partial w_{hid, out}} = \n",
    "    \\frac{\\partial E_{out}}{\\partial O_{out}} \\times \\frac{\\partial O_{out}}{w_{hid,out}} \\qquad (1)\n",
    "$$\n",
    "\n",
    "Допустим, мы имеем дело с квадратичной ошибкой: $E_{out}=(T_{out}-O_{out})^{2}$, где $T_{out}$ - это target.\n",
    "\n",
    "В таком случае первый член выражения (1):\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial E_{out}}{\\partial O_{out}} = -2 \\times (T_{out}-O_{out})\n",
    "$$\n",
    "\n",
    "Так же предположим, что функция активации - сигмиоида ($sigm(x)$), тогда поскольку $sigm(x)'=sigm(x)\\times (1-sigm(x))$, то второй множитель выражения (2):\n",
    "$$\n",
    "    \\frac{\\partial O_{out}}{\\partial W_{hid, out}} = \n",
    "    sigm \\Big(\\sum_{hid}w_{hid, out}O_{hid}\\Big) \\times \\Big(1 - sigm \\Big(\\sum_{hid}w_{hid, out}O_{hid}\\Big)\\Big) \\times O_{hid}\n",
    "$$\n",
    "\n",
    "Таким образом окончательный вид градиента:\n",
    "$$\n",
    "    \\frac{\\partial E_{out}}{\\partial W_{hid, out}} = \n",
    "    -2 \\times (T_{out}-O_{out}) \\times\n",
    "    sigm \\Big(\\sum_{hid}w_{hid, out}O_{hid}\\Big) \\times \\Big(1 - sigm \\Big(\\sum_{hid}w_{hid, out}O_{hid}\\Big)\\Big) \\times O_{hid}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронная сеть (3 слоя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_noes, \n",
    "                 hidden_nodes, \n",
    "                 out_nodes, \n",
    "                 learning_rate, \n",
    "                 activation_function = lambda x: scipy.special.expit(x)\n",
    "                ):\n",
    "        self.inodes = input_noes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = out_nodes\n",
    "        \n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        # Задаются как выборка из нормального распределения с центром в нуле, и мат. ожиданием равным\n",
    "        # 1. / (корень квадратный из количества узлов)\n",
    "        # Weights between input and hidden layers\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        # Weights between hidden and output layers\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        # Activation function\n",
    "        self.act_func = activation_function\n",
    "    \n",
    "    # NW train function\n",
    "    def train(self, input_list, target_list):\n",
    "        inputs = np.array(input_list, ndmin = 2).T\n",
    "        targets = np.array(target_list, ndmin = 2).T\n",
    "        \n",
    "        # Caluclate output of hidden layer\n",
    "        hidden_input = np.dot(self.wih, inputs)\n",
    "        hidden_output = self.act_func(hidden_input)\n",
    "        \n",
    "        # Calculate output of output layers\n",
    "        out_input = np.dot(self.who, hidden_output)\n",
    "        out_output = self.act_func(out_input)\n",
    "        \n",
    "        # Calculate error of output layer\n",
    "        out_errors = targets - out_output\n",
    "        \n",
    "        # Reverse error correction on output->hidden layer\n",
    "        hidden_errors = np.dot(self.who.T, out_errors)\n",
    "        self.who += self.lr * np.dot( (out_errors * out_output * (1.0 - out_output)), np.transpose(hidden_output) )\n",
    "        \n",
    "        # Reverse error correction on hidden->input layer\n",
    "        self.wih += self.lr * np.dot( (hidden_errors * hidden_output * (1.0 - hidden_output)), np.transpose(inputs) )\n",
    "        \n",
    "    \n",
    "    # Calculate output results based on choosen 'input_list' data\n",
    "    def query(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin = 2).T\n",
    "        \n",
    "        hidden_input = np.dot(self.wih, inputs)\n",
    "        hidden_output = self.act_func(hidden_input)\n",
    "        \n",
    "        out_input = np.dot(self.who, hidden_output)\n",
    "        out_output = self.act_func(out_input)\n",
    "        \n",
    "        return out_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Number of repetition for NW on single dataset\n",
    "epoch_number = 5\n",
    "\n",
    "train_file_path = os.path.join(os.getcwd(), 'mnist_dataset', 'mnist_train.csv')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nw = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "    \n",
    "    # Prepare trainig data\n",
    "    trainig_data_file = open(train_file_path, 'r')\n",
    "    train_data_list = trainig_data_file.readlines()\n",
    "    trainig_data_file.close()\n",
    "    \n",
    "    for i in range(epoch_number):\n",
    "        for record in train_data_list:\n",
    "            all_values = record.split(',')\n",
    "            # Create data for input nodes\n",
    "            # Convert from [0,255] range to [0.01, 1.0]\n",
    "            input_data = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "\n",
    "            # Create output targets\n",
    "            # If output is 5 -> [0.01, 0.01, 0.01, 0.01, 0.99, 0.01, 0.01, 0.01, 0.01,]\n",
    "            output_data = np.zeros(output_nodes) + 0.01\n",
    "            output_data[int(all_values[0])] = 0.99\n",
    "\n",
    "            nw.train(input_data, output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NW efficiency: 0.962\n"
     ]
    }
   ],
   "source": [
    "test_file_path = os.path.join(os.getcwd(), 'mnist_dataset', 'mnist_test.csv')\n",
    "\n",
    "test_data_file = open(test_file_path, 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "scores = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    for record in test_data_list:\n",
    "        test_values = record.split(',')\n",
    "        test_input = (np.asfarray(test_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        expected_value = int(test_values[0])\n",
    "        \n",
    "        train_values = nw.query(test_input)\n",
    "        \n",
    "        if expected_value == np.argmax(train_values):\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    \n",
    "    scores = np.asarray(scores)\n",
    "    print('NW efficiency: {0}'.format(float(np.sum(scores)) / float(scores.size)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейронная сеть, которая рисует цифры\n",
    "\n",
    "\n",
    "Параметры нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 10\n",
    "hidden_nodes = 100\n",
    "output_nodes = 784\n",
    "\n",
    "learning_rate = 0.1\n",
    "activation_function = lambda x: scipy.special.expit(x)\n",
    "\n",
    "epoch_numb = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необходимые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    '''\n",
    "        Read incoming MNIST dataset\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        raise Exception('Path: {0} does not exists'.format(path))\n",
    "    \n",
    "    with open(path) as f:\n",
    "        return f.readlines()\n",
    "\n",
    "def display_number(data):\n",
    "    '''\n",
    "        Displays number as a picture.\n",
    "    '''\n",
    "    if data.shape[0] != 784:\n",
    "        raise Exception('Wrong input data.')\n",
    "    plt.imshow(data.reshape(28, 28), cmap='Greys', interpolation='None')\n",
    "    plt.show()\n",
    "\n",
    "def normalize(data):\n",
    "    '''\n",
    "        Normalize the output data.\n",
    "    '''\n",
    "    if data.shape[0] != 784:\n",
    "        raise Exception('Wrong input data.')\n",
    "    return data / 255.0 * 0.99 + 0.01\n",
    "\n",
    "def train_all(nw, input_data, epoch_numb=1):\n",
    "    '''\n",
    "        Train NN on all incoming data\n",
    "    '''\n",
    "    for i in range(epoch_numb):\n",
    "        # Train on incoming set of data\n",
    "        for line in input_data:\n",
    "            data = line.split(',')\n",
    "            # Prepare input for NN \n",
    "            input_list = np.zeros(10) + 0.01\n",
    "            input_list[int(data[0])] = 0.99\n",
    "            # Prepare target for NN\n",
    "            target_list = normalize(np.asfarray(data[1:]))\n",
    "            nw.train(input_list, target_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 285.4944634437561\n"
     ]
    }
   ],
   "source": [
    "# Path to dataset\n",
    "file_path = os.path.join(os.getcwd(), 'mnist_dataset', 'mnist_train.csv')\n",
    "\n",
    "nw = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate, activation_function)\n",
    "\n",
    "try:\n",
    "    input_data = read_data(file_path)\n",
    "    start = time.time()\n",
    "    train_all(nw, input_data, epoch_numb)\n",
    "    print('Train time: {0}'.format(time.time() - start))\n",
    "except Exception as e:\n",
    "    print('Error: ', str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number =  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = np.zeros(10) + 0.01\n",
    "test[0] = 0.99\n",
    "\n",
    "picture = nw.query(test)\n",
    "p = np.array(list(map(lambda x: round(x), np.ravel(picture))))\n",
    "print('Number = ', np.argmax(test))\n",
    "display_number(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
